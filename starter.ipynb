{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to activate the `metaflow-structured-data` environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow\n",
    "from metaflow import S3, profile\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"s3://outerbounds-datasets/ubiquant/investment_ids\"\n",
    "N_FILES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {}\n",
    "\n",
    "with profile(\"read\", stats_dict=stats):\n",
    "    with S3() as s3:\n",
    "\n",
    "        files = list(s3.list_recursive([url]))[:N_FILES]\n",
    "        total_size = sum(f.size for f in files) / 1024**3\n",
    "        print(\"Loading %2.1dGB of data\" % total_size)\n",
    "        stats = {}\n",
    "\n",
    "        with profile('download', stats_dict=stats):\n",
    "            loaded = s3.get_many([f.url for f in files])\n",
    "        _print_throughput(\"S3->EC2 download\", stats, total_size)\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=num_threads) as exe:\n",
    "            tables = exe.map(lambda f: pq.read_table(f, use_threads=False), files)\n",
    "            table = pyarrow.concat_tables(tables)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DuckDB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relational API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import duckdb\n",
    "\n",
    "COLUMN = \"f_0\"\n",
    "\n",
    "# Reads Parquet File to an Arrow Table\n",
    "arrow_table = pq.read_table('train_low_mem.parquet')\n",
    "\n",
    "# Transforms Arrow Table -> DuckDB Relation\n",
    "rel_from_arrow = duckdb.arrow(arrow_table)\n",
    "\n",
    "# we can run a SQL query on this and print the result\n",
    "res = rel_from_arrow.query('arrow_table', f'SELECT {COLUMN} FROM arrow_table;')\n",
    "\n",
    "# Transforms DuckDB Relation -> Arrow Table\n",
    " arrow_table_from_duckdb = rel_from_arrow.arrow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Directly with SQL + Replacement scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect()\n",
    "res = con.execute(f'SELECT {COLUMN} FROM arrow_table;').fetch_arrow_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "- [‚è´ Fast Data Loading and Low Mem with Parquet Files](https://www.kaggle.com/code/robikscube/fast-data-loading-and-low-mem-with-parquet-files)\n",
    "- https://gist.github.com/simicd/f0e8fcd277bb3fa932369551b97d5b07\n",
    "- [DuckDB quacks Arrow: A zero-copy data integration between Apache Arrow and DuckDB](https://duckdb.org/2021/12/03/duck-arrow.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metaflow-structured-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
